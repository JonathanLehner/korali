#include "modules/problem/bayesian/latent/hierarchicalLowlevel/hierarchicalLowlevel.hpp"
#include "sample/sample.hpp"

#include <map>
#include <math.h>

#include <gsl/gsl_blas.h>
#include <gsl/gsl_linalg.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_vector.h>

#include <fstream>
#include <iostream>

/* The problem initialization.*/
void korali::problem::bayesian::latent::HierarchicalLowlevel::initialize()
{
  korali::problem::bayesian::Latent::initialize();

  _normalLatentIndices.clear();
  _lognormalLatentIndices.clear();
  _logitnormalLatentIndices.clear();

  _latentIndex.clear();

  _hyperparametersMean.clear();
  _hyperparametersMean.resize(_latentSpaceDimensions);
  _hyperparametersCovariance.clear();
  _hyperparametersCovariance.resize(_latentSpaceDimensions * _latentSpaceDimensions);

  /* Check and assign distribution types , by looking only at those of the first individual. */
  size_t dim_counter = 0;
  for (size_t i = 0; i < _k->_variables.size() && (dim_counter < _latentSpaceDimensions); i++)
  {
    bool recognizedDistribution = false;
    auto var = _k->_variables[i];
    if (var->_individualIndex == 0 && var->_bayesianType == "Latent")
    {
      dim_counter++;
      std::string distribString = var->_latentVariableDistributionType;
      int latentCoord = var->_latentSpaceCoordinate;
      _latentVariableDistributions[var->_latentSpaceCoordinate] = var->_latentVariableDistributionType;
      _firstIndividualLatentIndices[var->_latentSpaceCoordinate] = i;

      if (distribString == "Normal")
      {
        _normalLatentIndices.push_back(latentCoord);
        recognizedDistribution = true;
      }
      if (distribString == "Log-Normal")
      {
        _lognormalLatentIndices.push_back(latentCoord);
        recognizedDistribution = true;
      }
      if (distribString == "Logit-Normal")
      {
        _logitnormalLatentIndices.push_back(latentCoord);
        recognizedDistribution = true;
      }
      if (distribString == "NA")
      {
        KORALI_LOG_ERROR("Each latent variable must be either normally, log-normally or logit-normally distributed. NA is only for internal use.");
      }
      if (recognizedDistribution == false) KORALI_LOG_ERROR("Unrecognized distribution type: %s.\n", distribString.c_str());
    }
  }
  if (dim_counter < _latentSpaceDimensions)
    KORALI_LOG_ERROR("Latent variable list was incomplete, expected exactly as many latent variables for individual 0 as there are latent space dimensions. Latent space dimensions: %d; number of variables for individual 0: %d; total number variables: %d (most likely more than the latent space dimension, but should not be less)",
                     _latentSpaceDimensions,
                     dim_counter,
                     _k->_variables.size());

  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    // Check variable type and that distributions aren't misassigned
    auto var = _k->_variables[i];
    std::string typeString = var->_bayesianType;
    std::string distribString = var->_latentVariableDistributionType;
    if (typeString != "Latent" && typeString != "Hyperparameter") KORALI_LOG_ERROR("Unrecognized Variable Type %s \n", typeString.c_str());
    int distribIndex = var->_latentSpaceCoordinate;
    if (_latentVariableDistributions[distribIndex] != distribString)
      if (!(typeString == "Hyperparameter" && distribString == "NA"))
        KORALI_LOG_ERROR("Assigned two+ latent variables to the same coordinate (same 'Latent Space Coordinate'), but declared different distribution types for both.");

    // store pointers to hyperparameter variables in an easier form
    if (typeString == "Hyperparameter")
    {
      if (var->_isMean)
      {
        _hyperparametersMean[var->_latentSpaceCoordinate] = _k->_variables[i];
      }
      else
      {
        // ! Note: If _diagonalCovariance, this will contain uninitialized values off-diagonal.
        if (_diagonalCovariance & (var->_covarianceI != var->_covarianceJ))
          KORALI_LOG_ERROR("Diagonal covariance expected, because the problem was defined as having diagonal covariance");
        _hyperparametersCovariance[var->_covarianceI * _latentSpaceDimensions + var->_covarianceJ] = _k->_variables[i];
      }
    }
  }

  /* Check the distribution indices and individual indices.
       For each distribution index, there should be the same number of 'individual' indices.
       Then create lists to keep track of them. */
  std::vector<int> sortedDistribIndices(0);
  std::vector<int> sortedIndividualIndices(0);
  for (auto var : _k->_variables)
    if (var->_bayesianType == "Latent") // Hyperparameters might have latent space coordinates assigned reasonably or might not - covariance matrix variables don't have a coordinate assigned (they have two)
      sortedDistribIndices.push_back(var->_latentSpaceCoordinate);
  for (auto var : _k->_variables)
    if (var->_bayesianType == "Latent") // Only latent variables are assigned to individuals.
      sortedIndividualIndices.push_back(var->_individualIndex);
  std::sort(sortedDistribIndices.begin(), sortedDistribIndices.end());
  std::sort(sortedIndividualIndices.begin(), sortedIndividualIndices.end());
  sortedDistribIndices.erase(unique(sortedDistribIndices.begin(), sortedDistribIndices.end()), sortedDistribIndices.end());
  sortedIndividualIndices.erase(unique(sortedIndividualIndices.begin(), sortedIndividualIndices.end()), sortedIndividualIndices.end());
  if (_latentSpaceDimensions != sortedDistribIndices.size()) KORALI_LOG_ERROR("Expected the utilized latent space coordinates to range from zero to one below the latent space dimension. Found too many or too few latent space coordinates in total.");
  if (_numberIndividuals != sortedIndividualIndices.size()) KORALI_LOG_ERROR("Expected the utilized individual indices to range from zero to one below the number of individuals. Found too many or too few individual indices in total.");

  _latentIndex.resize(_numberIndividuals);
  for (size_t i = 0; i < _numberIndividuals; i++)
    _latentIndex[i].resize(_latentSpaceDimensions);
  int expectedNumberVariables = 0;
  if (_diagonalCovariance)
    expectedNumberVariables = _latentSpaceDimensions * _numberIndividuals + _latentSpaceDimensions * 2;
  else
    expectedNumberVariables = _latentSpaceDimensions * _numberIndividuals + _latentSpaceDimensions + _latentSpaceDimensions * _latentSpaceDimensions;
  if (_k->_variables.size() != expectedNumberVariables)
    KORALI_LOG_ERROR("Error: For each coordinate of each 'individual' latent variable vector, one (latent) variable needs to be defined, and then we also need the right amount of hyperparameters (a mean vector and a covariance matrix /  its diagonal entries only if _diagonalCovariance).");

  // * Check that the ranges are from 0 to max
  std::map<int, std::vector<int>> latentCoordinatesPerIndividual;
  for (auto var : _k->_variables)
  {
    if (latentCoordinatesPerIndividual.count(var->_individualIndex) == 0)
    {
      latentCoordinatesPerIndividual.insert(std::make_pair(var->_individualIndex, std::vector<int>()));
      // latentCoordinatesPerIndividual[var->_individualIndex] = std::vector<int>(0);
      latentCoordinatesPerIndividual.at(var->_individualIndex).clear();
      latentCoordinatesPerIndividual.at(var->_individualIndex).push_back(var->_latentSpaceCoordinate);
    }
    else
      latentCoordinatesPerIndividual.at(var->_individualIndex).push_back(var->_latentSpaceCoordinate);
  }
  for (size_t i = 0; i < _numberIndividuals; i++)
  {
    if (std::find(sortedIndividualIndices.begin(), sortedIndividualIndices.end(), i) == sortedIndividualIndices.end())
      KORALI_LOG_ERROR("Error: Expected contiguous range of individual-indices. This index was missing: %d", i);
    for (size_t j = 0; j < _latentSpaceDimensions; j++)
    {
      if (std::find(latentCoordinatesPerIndividual[i].begin(), latentCoordinatesPerIndividual[i].end(), j) == latentCoordinatesPerIndividual[i].end())
        KORALI_LOG_ERROR("Error: A latent space coordinate (%d) was not present for any variable with 'Individual Index' %d. We need each 'coordinate' once for each individual.", j, i);
    }
  }

  // * Set up a 2D index for easier latent variable access
  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    if (_k->_variables[i]->_bayesianType == "Latent")
    {
      int i_idx = _k->_variables[i]->_individualIndex;
      int d_idx = _k->_variables[i]->_latentSpaceCoordinate;
      _latentIndex[i_idx][d_idx] = i;
    }
  }
}

/*! @brief Evaluate each log-likelihood log(p(data for individual i | latent variables i)) across all data points
            assigned to the individual, given latent variables.
            Uses sample["Latent Variables"] which must be a vector of vectors of latent variables (one vector per individual).
            Note: "Latent Variables" will be overwritten in the process!
     @param sample: sample["Latent Variables"] should contain a list of lists / vector of vectors, one latent variable vector for each individual.
     @param zForm:  A boolean indicating whether the latent variables are passed in z-Form (if zForm is true) or
                    whether "Latent Variables" are the untransformed values.
     @returns : sample["logLikelihood"], a list/vector with one log-likelihood per individual.
     */
void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLoglikelihood_(korali::Sample &sample, bool zForm)
{
  std::vector<std::vector<double>> allLatentVars = KORALI_GET(std::vector<std::vector<double>>, sample, "Latent Variables");
  assert(allLatentVars.size() == _numberIndividuals);
  if (zForm)
  {
    for (size_t i = 0; i < _numberIndividuals; i++)
    {
      std::vector<double> latentVars = allLatentVars[i];
      allLatentVars[i] = zToLatent(allLatentVars[i]);
    }
    sample["Latent Variables"] = allLatentVars;
  }
  sample.run(_logLikelihoodFunction);
  auto allLogP = KORALI_GET(std::vector<double>, sample, "logLikelihood");

  sample["logLikelihood"] = allLogP;
}
void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLoglikelihood(korali::Sample &sample)
{
  evaluateLoglikelihood_(sample, true);
}

/*! @brief Evaluate the "prior" log-probability of the transformed latent variables, given hyperparameters (mean and covariance matrix).
    @param sample: Is expected to contain the fields ["Latent Variables"], ["Mean"] and ["Covariance Matrix"]. Here, "Mean" should be
                    a vector (size := n), "Covariance Matrix" should be an nxn vector of vectors. (No special encoding of the covariance.)
                    "Latent Variables" should be a vector of vectors, one * transformed * latent variable vector per individual. The order is
                    assumed to be the same as the order of variables according to their indices at problem definition
                    (["Variables"][THE_INDEX]["some property"] = ...).
    @param zForm:  A boolean indicating whether the latent variables are passed in z-Form (if zForm is true) or
                    whether "Latent Variables" are the untransformed values.
                    Todo: Refactor to use "Hyperparameters" instead of "Mean" and "Covariance"?

        Update: This uses korali's multivariate normal distribution and comes with the option to pass an already
                cholesky-decomposed covariance.
 */
void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLogPrior_(korali::Sample &sample, bool zForm, bool cholesky)
{
  std::vector<std::vector<double>> _latentVariables = KORALI_GET(std::vector<std::vector<double>>, sample, "Latent Variables");
  std::vector<double> mean = KORALI_GET(std::vector<double>, sample, "Mean");
  size_t N = mean.size(); // Number of latent variables
  std::vector<std::vector<double>> covMatrix;
  if (cholesky)
  {
    covMatrix = KORALI_GET(std::vector<std::vector<double>>, sample, "Covariance Cholesky Decomposition");
  }
  else
  {
    covMatrix = KORALI_GET(std::vector<std::vector<double>>, sample, "Covariance Matrix");
  }
  if (_diagonalCovariance)
  {
    for (size_t i = 0; i < N; i++)
      for (size_t j = 0; j < N; j++)
      {
        if ((i != j) & covMatrix[i][j] != 0)
          KORALI_LOG_ERROR("Passed covariance or Cholesky decomposed covariance was not diagonal, but the problem was initialized as having diagonal covariance in the prior.");
      }
  }
  assert(N == covMatrix.size());       // "Error: Dimensions of covariance matrix passed to evaluateLogLikelihood did not fit to dimensions of the mean passed ");
  assert(N == _latentSpaceDimensions); // "Error: Dimensions of the hyperparameters passed to evaluateLogLikelihood did not fit to the latent variable distribution defined during problem setup.")
  for (std::vector<double> v : covMatrix)
    assert(v.size() == N);

  /* We want to find:
     logp = log(1/(sqrt(2*pi)*det(cov))) - (latent - mean)'*cov*(latent - mean)
     Or:
     the multinomial-gaussian probability given cov, mean and the latent variables - product over all latent vars.
  */

  gsl_matrix *chol = gsl_matrix_alloc(N, N);
  gsl_matrix *covMatrixGSL = gsl_matrix_alloc(N, N);

  if (!cholesky)
  {
    for (size_t i = 0; i < N; i++)
      for (size_t j = 0; j < N; j++)
        gsl_matrix_set(covMatrixGSL, i, j, covMatrix[i][j]);

    gsl_matrix_memcpy(chol, covMatrixGSL);

    int status = gsl_linalg_cholesky_decomp1(chol); //lower triangular part + diagonal of chol afterwards contain L from the cholesky decomposition cov = L*L'
    if (status != 0)
    {
      if (status != 1) KORALI_LOG_ERROR("Status == 1 would have indicated an invalid input, such as not positive definite (e.g. very small eigenvalues). But the GSL error code was: %d. Please report this if you think it is a bug.", status, status);
      /* TODO: If you rewrite hSAEM entirely so that it calls a sub-solver , hSAEMLowlevel or so, then, and only then, can
         *       you enable the line below: */
      //_k->_logger->logWarning("Normal", "Estimated covariance matrix was not positive definite.");
      /* If status == 1, covMatrixGSL was not positive definite.
         * Let's add a small diagonal matrix. */
      double eps = 1.e-4; // 1.e-8 is too small. Maybe GSL has low precision for matrix operations?
      for (size_t i = 0; i < N; i++)
      {
        for (size_t j = 0; j < N; j++)
          gsl_matrix_set(chol, i, j, covMatrix[i][j]);
        gsl_matrix_set(chol, i, i, covMatrix[i][i] + eps);
      }
      int status = gsl_linalg_cholesky_decomp1(chol); //lower triangular part + diagonal of chol afterwards contain L from the cholesky decomposition cov = L*L'

      if (status != 0) // Now it failed for real. Is it negative definite?
        KORALI_LOG_ERROR("GSL error code: %d. If ==1: Covariance matrix was invalid; this could mean it had a negative eigenvalue (that should be impossible) or one of its entries was NaN. Please report this if you think it is a bug.", status);
    }
  }
  else
  {
    for (size_t i = 0; i < N; i++)
    {
      for (size_t j = 0; j < N; j++)
      {
        gsl_matrix_set(chol, i, j, covMatrix[i][j]);
      }
    }
  }

  // Initialize the distribution:
  std::vector<double> sigmaVec(N * N);
  for (size_t i = 0; i < N; i++)
  {
    for (size_t j = 0; j < N; j++)
    {
      sigmaVec[i * N + j] = gsl_matrix_get(chol, i, j);
    }
  }
  _multivariateNormalDistribution->_meanVector = mean;
  _multivariateNormalDistribution->_sigma = sigmaVec;
  _multivariateNormalDistribution->updateDistribution();

  /* Calculate the log-probability for each individual, meaning each of the transformed-latent-variable vectors
  following the same multivariate Gaussian distribution */
  std::vector<double> individualLLH(_numberIndividuals);
  for (size_t i = 0; i < _numberIndividuals; i++)
  {
    // Get i-th vector of latent variables:
    std::vector<double> latentZ = _latentVariables[i];
    if (!zForm)
      latentZ = latentToZ(latentZ);
    double logP = 0;
    _multivariateNormalDistribution->getLogDensity(&latentZ[0], &logP, latentZ.size());
    individualLLH[i] = logP;
  }
  gsl_matrix_free(chol);
  gsl_matrix_free(covMatrixGSL);

  sample["Log Prior"] = individualLLH;
}
//
//        This older function essentially implements a multivariate normal probability function. But that is already
//                implemented in the distribution multivariate/normal. Although this old function seemed to work
//                just as well, switched to the "simpler" version.
//void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLogPrior_old(korali::Sample &sample, bool zForm)
//{
//  //  volatile int done = 0;
//  //  while (!done) sleep(1);
//
//  // calculate log[ p(latent | hyperparams) ]:
//  // -- need a multivariate log-gaussian function for this
//  // += conditional log-llh (log[p(data | latent)])
//
//  std::vector<std::vector<double>> _latentVariables = KORALI_GET(std::vector<std::vector<double>>, sample, "Latent Variables");
//  std::vector<double> mean = KORALI_GET(std::vector<double>, sample, "Mean");
//  size_t N = mean.size(); // Number of latent variables
//  auto covMatrix = KORALI_GET(std::vector<std::vector<double>>, sample, "Covariance Cholesky Decomposition");
//  assert(N == covMatrix.size());       // "Error: Dimensions of covariance matrix passed to evaluateLogLikelihood did not fit to dimensions of the mean passed ");
//  assert(N == _latentSpaceDimensions); // "Error: Dimensions of the hyperparameters passed to evaluateLogLikelihood did not fit to the latent variable distribution defined during problem setup.")
//  for (std::vector<double> v : covMatrix)
//    assert(v.size() == N);
//
//  //gsl_matrix_const_view covMatrixGSL = gsl_matrix_const_view_array(&covMatrix[0][0], N, N); // This works, but for memcopy below we need a proper matrix
//  gsl_matrix *covMatrixGSL = gsl_matrix_alloc(N, N);
//  for (size_t i = 0; i < N; i++)
//    for (size_t j = 0; j < N; j++)
//      gsl_matrix_set (covMatrixGSL, i, j, covMatrix[i][j]);
//
//  // First, calculate the cholesky decomposition, cov = L'*L
//  gsl_matrix *chol = gsl_matrix_alloc(N, N);
//  gsl_matrix_memcpy(chol, covMatrixGSL);
//
//  int status = gsl_linalg_cholesky_decomp1(chol); //lower triangular part + diagonal of chol afterwards contain L from the cholesky decomposition cov = L*L'
//  if (status != 0){
//    if (status != 1)  KORALI_LOG_ERROR("Status == 1 would have indicated an invalid input, such as not positive definite (e.g. very small eigenvalues). But the GSL error code was: %d. Please report this if you think it is a bug.", status, status);
////    assert(status == 1);
//    /* TODO: If you rewrite hSAEM entirely so that it calls a sub-solver , hSAEMLowlevel or so, then, and only then, can
//     *       you enable the line below: */
//    //_k->_logger->logWarning("Normal", "Estimated covariance matrix was not positive definite.");
//    /* If status == 1, covMatrixGSL was not positive definite.
//     * Let's add a small diagonal matrix. */
//    double eps = 1.e-4; // 1.e-8 is too small. Maybe GSL has low precision for matrix operations?
//    for (size_t i = 0; i < N; i++){
//      for (size_t j = 0; j < N; j++)
//        gsl_matrix_set (chol, i, j, covMatrix[i][j]);
//      gsl_matrix_set (chol, i, i, covMatrix[i][i] + eps);
//    }
//    int status = gsl_linalg_cholesky_decomp1(chol); //lower triangular part + diagonal of chol afterwards contain L from the cholesky decomposition cov = L*L'
//
//    if(status != 0) // Now it failed for real. Is it negative definite?
//      KORALI_LOG_ERROR("GSL error code: %d. If ==1: Covariance matrix was invalid; this could mean it had a negative eigenvalue (that should be impossible) or one of its entries was NaN. Please report this if you think it is a bug.", status);
//  }
//
//  // --> log(det(covariance)) = sum(log( diag(L) ))
//  double logdet = 0;
//  for (size_t i = 0; i < N; i++)
//  {
//    logdet += log(gsl_matrix_get(chol, i, i));
//    // We swallow the 2* and drop 1/2* further down (det(Sigma) = det(chol)**2 and we later take the root).
//  }
//
//  // we'll need those
//  gsl_vector_const_view mean_view = gsl_vector_const_view_array(&mean[0], N);
//  gsl_vector *latent_minus_mean = gsl_vector_alloc(N);
//  gsl_vector *x = gsl_vector_alloc(N);
//  std::vector<double> individualLLH(_numberIndividuals);
//  //  double lllh = 0;
//  //gsl_vector_const_view b(&latent_minus_mean, N);
//  //gsl_vector* b = gsl_vector_alloc(N);
//
//  /* Calculate the log-probability for each individual, meaning each of the transformed-latent-variable vectors
//   following the same multivariate Gaussian distribution */
//  for (size_t i = 0; i < _numberIndividuals; i++)
//  {
//    // Get i-th vector of latent variables:
//    std::vector<double> latentZ = _latentVariables[i];
//    if (!zForm)
//      latentZ = latentToZ(latentZ);
//    for (size_t j = 0; j < _latentSpaceDimensions; j++)
//    {
//      //size_t v_idx = _latentIndex[i][j];
//      gsl_vector_set(latent_minus_mean, j, latentZ[j]);
//    }
//
//    gsl_vector_sub(latent_minus_mean, &mean_view.vector); // todo: &... or just mean_view.vector?
//    //std::vector<double> latent_minus_mean(_latentVariables); // should copy -?
//    //std::transform(latent_minus_mean.begin(), latent_minus_mean.end(), mean.begin(), latent_minus_mean.begin(), std::minus<double>());
//
//    //  // for inversion/solving a linear eqation, could add a small positive diagonal matrix:
//    //  double eps = 1.e-10;
//    //  gsl_matrix* epsMatrix = gsl_matrix_alloc(N, N);
//    //  gsl_matrix_set_identity(epsMatrix);
//    //  gsl_matrix_scale(epsMatrix, eps);
//
//    // * "Invert" the covariance matrix using the cholesky decomposition cov = L'*L (solve a LSE for each 'individual')
//    gsl_linalg_cholesky_solve(chol, latent_minus_mean, x); // -> x = Cov^-1 * (latent - mean)
//
//    // --> log(p( latent | mean, cov )) = || (latent - mean)*L^-1 ||^2 / 2
//    //                                  = (latent - mean)^T * cov^-1 / 2 * (latent - mean)
//    double lllh_i;
//    gsl_blas_ddot(latent_minus_mean, x, &lllh_i);
//    //    lllh -= lllh_i / 2.;
//    individualLLH[i] -= lllh_i / 2.;
//  }
//
//  // add the log of the normalization factor:
//  double log_normn = (float(N) / 2. * log(2. * M_PI) + logdet);
//  for (size_t i = 0; i < _numberIndividuals; i++)
//    individualLLH[i] -= log_normn;
//  //  lllh -= log_normn * float(_numberIndividuals);
//  //  sample["Log Prior"] = lllh;
//  sample["Log Prior"] = individualLLH;
//
//  gsl_matrix_free(covMatrixGSL);
//  gsl_matrix_free(chol);
//  gsl_vector_free(latent_minus_mean);
//  gsl_vector_free(x);
//}

void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLogPrior(korali::Sample &sample)
{
  evaluateLogPrior_(sample, true, true);
}

/*! @brief Evaluate the total loglikelihood of the data (implicitly included in the likelihood function definition),
            given values for latent variables and hyperparameters.
    @param sample: Is expected to contain the fields ["Latent Variables"], ["Mean"] and ["Covariance Matrix"] or
                    ["Covariance Cholesky Decomposition"]. Latent variables should be in untransformed form.
                    "Mean" should be a vector (size := n), "Covariance Matrix" or "Covariance Cholesky Decomposition" should be an
                    nxn vector of vectors. (No special encoding of the cov except as cholesky decomp..)
                    Todo: Refactor to use "Hyperparameters" instead of "Mean" and "Covariance .."?
         TODO: test it.
 */
void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLogPosterior_(korali::Sample &sample, bool zForm, bool cholesky)
{
  evaluateLogPrior_(sample, zForm, cholesky);
  evaluateLoglikelihood_(sample, zForm);

  auto llhs = KORALI_GET(std::vector<double>, sample, "logLikelihood");
  auto lpriors = KORALI_GET(std::vector<double>, sample, "Log Prior");

  //               log(p) =         log(p(y | latent))                   + log(p(latent | hyperparams))
  sample["Log Posterior"] = std::accumulate(llhs.begin(), llhs.end(), 0) + std::accumulate(lpriors.begin(), lpriors.end(), 0);
}
void korali::problem::bayesian::latent::HierarchicalLowlevel::evaluateLogPosterior(korali::Sample &sample)
{
  evaluateLogPosterior_(sample, true, true);
}

std::vector<double> korali::problem::bayesian::latent::HierarchicalLowlevel::zToLatent(std::vector<double> z)
{
  if (z.size() != _latentSpaceDimensions)
    KORALI_LOG_ERROR("Error, z vector passed to zToLatent() had the wrong number of entries.");
  std::vector<double> theta(_latentSpaceDimensions);

  size_t counter = 0;
  for (size_t i : _normalLatentIndices)
  {
    theta[i] = z[i];
    counter++;
  }
  for (size_t i : _lognormalLatentIndices)
  {
    theta[i] = exp(z[i]);
    counter++;
  }
  for (size_t i : _logitnormalLatentIndices)
  {
    theta[i] = 1.0 / (1.0 + exp(-z[i])); // z= logit(theta)
    counter++;
  }
  assert(counter == _latentSpaceDimensions); // Else implementation error. The indices overlap, that should not be possible.
                                             //  for (size_t i=0; i<theta.size(); i++)
                                             //    assert(!isinf(theta[i]));
  return theta;
}

std::vector<double> korali::problem::bayesian::latent::HierarchicalLowlevel::latentToZ(std::vector<double> v)
{
  if (v.size() != _latentSpaceDimensions)
    KORALI_LOG_ERROR("Error, vector passed to latentToZ() had the wrong number of coordinates.");

  std::vector<double> z(_latentSpaceDimensions);
  size_t counter = 0;
  for (size_t i : _normalLatentIndices)
  {
    z[i] = v[i];
    counter++;
  }
  for (size_t i : _lognormalLatentIndices)
  {
    if (v[i] <= 0)
      KORALI_LOG_ERROR("Any value of a log-normally distributed variable needs to be in range [0, 1).");
    z[i] = log(v[i]);
    counter++;
  }
  for (size_t i : _logitnormalLatentIndices)
  {
    if ((v[i] < 0) || (v[i] >= 1))
      KORALI_LOG_ERROR("Any value of a logit-normally distributed variable needs to be in range [0, 1).");
    z[i] = log(v[i] / (1.0 - v[i]));
    counter++;
  }
  assert(counter == _latentSpaceDimensions); // Else implementation error. The indices overlap, that should not be possible.

  return z;
}
