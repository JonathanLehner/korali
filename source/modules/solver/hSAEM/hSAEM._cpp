#include "modules/solver/hSAEM/hSAEM.hpp"
#include "modules/conduit/conduit.hpp"


 /* @brief This is always run before (re-)starting the solver */
void korali::solver::HSAEM::initialize()
{

 if( _k->_problem->getType() != "Bayesian/Latent/HierarchicalLatent")
   _k->_logger->logError("SAEM can only optimize problems of type 'Bayesian/Latent/HierarchicalLatent' .\n");

  _latentProblem = dynamic_cast<korali::problem::bayesian::latent::HierarchicalLatent*>(_k->_problem);

    // Todo: make sure the problem is initialized before the solver
 _numberVariables = _k->_variables.size();
 _numberLatent = _latentProblem->_latentVariableIndices.size();
 _numberHyperparameters = _numberVariables - _numberLatent;

 for (size_t i = 0; i < _numberVariables; i++)
   if( std::isfinite(_k->_variables[i]->_initialValue) == false )
     _k->_logger->logError("Initial Value of variable \'%s\' not defined (no defaults can be calculated).\n", _k->_variables[i]->_name.c_str());

}

 /* @brief Run once, before the first generation */
void korali::solver::HSAEM::setInitialConfiguration()
{
  // resizing and clearing internal vector variables
 _currentSamples.clear();
 _currentSampleMeans.resize(_numberLatent);
 _currentSampleStandardDeviations.resize(_numberLatent);
 _currentS1.resize(_numberLatent);
 _currentS2.resize(_numberLatent);
 for (size_t i = 0; i < _numberLatent; i++)
   _currentS2[i].resize(_numberLatent);
 std::fill(_currentS1.begin(), _currentS1.end(), 0);
 for (size_t i = 0; i < _numberLatent; i++)
   std::fill(_currentS2[i].begin(), _currentS2[i].end(), 0);
 _currentCholesky.resize(_numberLatent);
 for (size_t i = 0; i < _numberLatent; i++)
    _currentCholesky[i].resize(_numberLatent);

//  volatile int done = 0;
//  while (!done) sleep(1);

  // Set starting values for hyperparameters - just copy them over, we already set them in the problem initialization
  _currentHyperparametersMean.resize(_numberLatent);
  _currentHyperparametersCovariance.resize(_numberLatent);
  for (size_t i = 0; i < _numberLatent; i++)
    _currentHyperparametersCovariance[i].resize(_numberLatent);
  size_t hyperparam_index = 0;
  for (size_t i = 0; i < _numberLatent; i++)
  {
//    int idx =  _latentProblem->_hyperparameterMeanIndices[i];
    _currentHyperparametersMean[i] = _latentProblem->_hyperparameterMean[i]->_initialValue;
  }
  for (size_t i = 0; i < _numberLatent; i++)
    for (size_t j = 0; j < _numberLatent; j++)
    {
      int idx =  _latentProblem->_hyperparameterCovIndices[i][j];
      _currentHyperparametersCovariance[i][j] = _latentProblem->_hyperparameterCovariance[idx]->_initialValue;
    }

  _bestLogLikelihood = -korali::Inf;

}

void korali::solver::HSAEM::runGeneration()
{
 if (_k->_currentGeneration == 1) setInitialConfiguration();

 _k->_logger->logInfo("Normal", "Running generation %lu...\n", _k->_currentGeneration);

 justTesting();

 /* E1: Sample latent variable values */
 sampleLatent();
 _k->_logger->logInfo("Detailed", "Sampled generation: %d \n", _k->_currentGeneration);

 /* E2: Update posterior probability function Q */
 updateS();

 /* M:  Find argmax Q(theta), analytically */
 updateHyperparameters();
 updateCholesky();

}



/* initial things to run to test the hierarchical latent problem class */
void korali::solver::HSAEM::justTesting()
{
// for simple population example: Only means of the data, 1-dimensional
 size_t nIndividuals = 10;
 std::vector<double> latent_vars = {1.25, 1.25, 1.25, 1., 1., 1., 0.9, 0.75, 0.75, 0.75,};
 std::vector<double> mean = {1};
 std::vector<std::vector<double>> cov(1);
 cov[0] = std::vector<double>({0.5});
 // sigma (sdev of the distribution of which the latent variable is the mean), and the data points, are
 // set by the problem - we can't access them here

 korali::Sample sample;
 sample["Latent Variables"] = latent_vars;
 sample["Mean"] = mean ;
 sample["Covariance Matrix"] = cov;
 sample["Module"] = "Problem";
 sample["Operation"] = "Evaluate Conditional LogLikelihood";

  _conduit->start(sample);
  _conduit->wait(sample);

 // test evaluateConditionalLoglikelihood()

  sample["Operation"] = "Evaluate LogLikelihood";
  double cond_llh = sample["Conditional LogLikelihood"];
  _k->_logger->logInfo("Normal", "Test: Conditional LLLH = %f evaluated for latent variables:\n", cond_llh);
  for (size_t i = 0; i < _latentProblem->_latentVariableIndices.size(); i++){
    int idx = _latentProblem->_latentVariableIndices[i];
    _k->_logger->logInfo("Normal", "Test: \t %s : %e \n", _k->_variables[idx]->_name.c_str(), latent_vars[i]);
  }


 // test evaluateLoglikelihood()
  sample["Operation"] = "Evaluate LogLikelihood";
  _conduit->start(sample);
  _conduit->wait(sample);
  double llh = sample["LogLikelihood"];
  _k->_logger->logInfo("Normal", "Test: LLH = %f evaluated for latent variables as above, plus mean:\n", llh);
  for (size_t i = 0; i < mean.size(); i++){
    _k->_logger->logInfo("Normal", "Test: \t Mean %d: %e \n", i, mean[i]);
  }
  for (size_t i = 0; i < cov.size(); i++){
    for (size_t j = 0; j < cov[0].size(); j++){
    _k->_logger->logInfo("Normal", "Test: \t Cov[%d, %d]: %e \n", i, j, cov[i][j]);
  }
  }

}

void korali::solver::HSAEM::sampleLatent(){
}

void korali::solver::HSAEM::updateS(){
}

void korali::solver::HSAEM::updateHyperparameters(){
}

void korali::solver::HSAEM::updateCholesky(){
}


void korali::solver::HSAEM::printGenerationBefore()
{
 _k->_logger->logInfo("Normal", "Preparing to start generation...\n");
}

void korali::solver::HSAEM::printGenerationAfter()
{
 _k->_logger->logInfo("Normal", "Finished to generation %lu...\n", _k->_currentGeneration);
}

