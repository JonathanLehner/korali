#include "modules/solver/hSAEM/hSAEM.hpp"
#include "modules/conduit/conduit.hpp"


 /* @brief This is always run before (re-)starting the solver */
void korali::solver::HSAEM::initialize()
{

 if( (_k->_problem->getType() != "Bayesian/Latent/HierarchicalLatent") && (_k->_problem->getType() != "Bayesian/Latent/HierarchicalLatentLowlevel"))
   korali::Logger::logError("SAEM can only optimize problems of type 'Bayesian/Latent/HierarchicalLatent' or '.../HierarchicalLatentLowlevel' .\n");
 if (_k->_problem->getType() == "Bayesian/Latent/HierarchicalLatent"){
   _latentProblemWrapper = dynamic_cast<korali::problem::bayesian::latent::HierarchicalLatent*>(_k->_problem);
   _latentProblem = _latentProblemWrapper->_lowlevelProblem;
   }
 if (_k->_problem->getType() == "Bayesian/Latent/HierarchicalLatentLowlevel")
   _latentProblem = dynamic_cast<korali::problem::bayesian::latent::HierarchicalLatentLowlevel*>(_k->_problem);

    // Todo: make sure the problem is initialized before the solver
 _numberLatent = _k->_variables.size();
 _latentSpaceDimensions = _latentProblem->_latentSpaceDimensions;
// _numberHyperparameters = _latentSpaceDimensions * (1 + _latentSpaceDimensions);

 for (size_t i = 0; i < _numberLatent; i++)
   if( std::isfinite(_k->_variables[i]->_initialValue) == false )
     korali::Logger::logError("Initial Value of variable \'%s\' not defined (no defaults can be calculated).\n", _k->_variables[i]->_name.c_str());


}

 /* @brief Run once, before the first generation */
void korali::solver::HSAEM::setInitialConfiguration()
{
  // Resizing and clearing internal vectors
 _currentSamples.clear();
 _currentSampleMeans.resize(_latentSpaceDimensions);
 _currentZ.resize(_mcmcNumberChains);
 for (size_t i = 0; i < _latentSpaceDimensions; i++)
 _currentSampleStandardDeviations.resize(_latentSpaceDimensions);
 _currentS1.resize(_latentSpaceDimensions);
 _currentS2.resize(_latentSpaceDimensions);
 for (size_t i = 0; i < _latentSpaceDimensions; i++)
   _currentS2[i].resize(_latentSpaceDimensions);
 std::fill(_currentS1.begin(), _currentS1.end(), 0);
 for (size_t i = 0; i < _latentSpaceDimensions; i++)
   std::fill(_currentS2[i].begin(), _currentS2[i].end(), 0);
 _currentCholesky.resize(_latentSpaceDimensions);
 for (size_t i = 0; i < _latentSpaceDimensions; i++)
    _currentCholesky[i].resize(_latentSpaceDimensions);
 _mcmcVariances.resize(_latentSpaceDimensions);
 std::fill(_mcmcVariances.begin(), _mcmcVariances.end(), 1.0);
 _acceptanceRate = 1.;

 _annealedCovariance.resize(_latentSpaceDimensions * _latentSpaceDimensions);
 std::fill(_annealedCovariance.begin(), _annealedCovariance.end(), 0);
 for (size_t i = 0; i < _latentSpaceDimensions; i++)
   // diagonal matrix, flattened
   _annealedCovariance[i + i * _latentSpaceDimensions] = 1.0; // "high" initial covariance values; adjust if needed

//  volatile int done = 0;
//  while (!done) sleep(1);

  // Set starting values for hyperparameters - just copy them over, we already set them in the problem initialization
  _currentHyperparametersMean.resize(_latentSpaceDimensions);
  _currentHyperparametersCovariance.resize(_latentSpaceDimensions);
  for (size_t i = 0; i < _latentSpaceDimensions; i++)
    _currentHyperparametersCovariance[i].resize(_latentSpaceDimensions);
  size_t hyperparam_index = 0;
  for (size_t i = 0; i < _latentSpaceDimensions; i++)
  {
//    int idx =  _latentProblem->_hyperparametersMeanIndices[i];
    _currentHyperparametersMean[i] = _latentProblem->_hyperparametersMean[i]->_initialValue;
  }
  for (size_t i = 0; i < _latentSpaceDimensions; i++)
    for (size_t j = 0; j < _latentSpaceDimensions; j++)
    {
//      int idx =  _latentProblem->_hyperparametersCovIndices[i][j];
      int idx = i * _latentProblem->_latentSpaceDimensions + j;
      _currentHyperparametersCovariance[i][j] = _latentProblem->_hyperparametersCovariance[idx]->_initialValue;
    }

  updateAnnealedDistribution();
  for (size_t i = 0; i < _mcmcNumberChains; i++ ){
   // _currentZ[i].resize(_latentSpaceDimensions);
    std::vector<double> temp_something(1);
    _annealedNormalGenerator->getRandomVector(&_currentZ[i][0], _latentSpaceDimensions);
  }

  if (_latentSpaceDimensions == 1)
    _n3 = 0;

  _bestLogLikelihood = -korali::Inf;

}

void korali::solver::HSAEM::runGeneration()
{
 if (_k->_currentGeneration == 1) setInitialConfiguration();

 _k->_logger->logInfo("Normal", "Running generation %lu...\n", _k->_currentGeneration);

 justTesting();

 /* E1: Sample latent variable values */
 sampleLatent();
 _k->_logger->logInfo("Detailed", "Sampled generation: %d \n", _k->_currentGeneration);

 /* E2: Update posterior probability function Q */
 updateS();

 /* M:  Find argmax Q(theta), analytically */
 updateHyperparameters();
 updateCholesky();

}



/* initial things to run to test the hierarchical latent problem class */
void korali::solver::HSAEM::justTesting()
{
// for simple population example: Only means of the data, 1-dimensional
 size_t nIndividuals = 10;
 std::vector<double> latent_vars = {1.25, 1.25, 1.25, 1., 1., 1., 0.9, 0.75, 0.75, 0.75,};
 std::vector<double> mean = {1};
 std::vector<std::vector<double>> cov(1);
 cov[0] = std::vector<double>({0.5});
 // sigma (sdev of the distribution of which the latent variable is the mean), and the data points, are
 // set by the problem - we can't access them here

 korali::Sample sample;
 sample["Latent Variables"] = latent_vars;
 sample["Mean"] = mean ;
 sample["Covariance Matrix"] = cov;
 sample["Module"] = "Problem";
 sample["Operation"] = "Evaluate Conditional LogLikelihood";

  _conduit->start(sample);
  _conduit->wait(sample);

 // * test evaluateConditionalLoglikelihood()

  std::vector<double> cond_llh = sample["Conditional LogLikelihood"];
  _k->_logger->logInfo("Normal", "Test: Conditional LLLH = %f evaluated for latent variables:\n", cond_llh[0]); // Todo: adjust this to pring all of cond_llh
  for (size_t i = 0; i < _latentProblem->_latentVariableIndices.size(); i++){
    int idx = _latentProblem->_latentVariableIndices[i];
    _k->_logger->logInfo("Normal", "Test: \t %s : %e \n", _k->_variables[idx]->_name.c_str(), latent_vars[i]);
  }


 // * test evaluateLoglikelihood()
  sample["Operation"] = "Evaluate LogPosterior";
  _conduit->start(sample);
  _conduit->wait(sample);
  double llh = sample["LogPosterior"];
  _k->_logger->logInfo("Normal", "Test: LLH = %f evaluated for latent variables as above, plus mean:\n", llh);
  for (size_t i = 0; i < mean.size(); i++){
    _k->_logger->logInfo("Normal", "Test: \t Mean %d: %e \n", i, mean[i]);
  }
  for (size_t i = 0; i < cov.size(); i++){
    for (size_t j = 0; j < cov[0].size(); j++){
    _k->_logger->logInfo("Normal", "Test: \t Cov[%d, %d]: %e \n", i, j, cov[i][j]);
  }
  }

}

void korali::solver::HSAEM::sampleLatent(){

  updateAnnealedDistribution(); // because we want to draw from it below

  int NStepsPerChain = _mcmcOuterSteps * (_n1 + _n2 + _n3);
  std::vector<std::vector<std::vector<std::vector<double>>>> allSamples;
  //allSamples.clear();

  // Todo: Get current Log-Likelihood.


  // ** Loop over chains
  for (size_t c_idx = 0; c_idx < _mcmcNumberChains; c_idx++)
  {
    std::vector<std::vector<std::vector<double>>> chainSamples;
    //chainSamples.clear();

    // ** Chain initialization
    std::vector<std::vector<double>> eta(_latentProblem->_numberIndividuals); // NrIndividuals x NrDimensions
    for (size_t edx = 0; edx < _latentProblem->_numberIndividuals; edx++){
      eta[edx].resize(_latentSpaceDimensions);
      // current eta = current z - current mean
      std::transform(_currentZ[c_idx].begin(), _currentZ[c_idx].end(),
         _currentHyperparametersMean.begin(), eta[edx].begin(), std::minus<double>());
    }

    // ** Loop over one chain
    for (size_t step = 0; step < _mcmcOuterSteps; step++)
    {
      std::vector<std::vector<double>> stepSamples;  // NrIndividuals x NrDimensions
      //stepSamples.clear();

      // ** 1st proposal distribution
      for (size_t i = 0; i < _n1; i++)
      {
        // Proposals q1: Drawn from p(latent | hyperparam)
        std::vector<std::vector<double>> eta_new(_latentProblem->_numberIndividuals); // NrIndividuals x NrDimensions
        std::vector<double> temp_eta(_latentSpaceDimensions);
        for (size_t edx = 0; edx < _latentProblem->_numberIndividuals; edx++){
          _annealedNormalGenerator->getRandomVector(&temp_eta[0], _latentSpaceDimensions);// == Previous samples minus par.beta --Why?
          eta_new[edx] = temp_eta;
        }
      /* Todo:
         What George's code does:
          -  sample jointly for all individuals and all dimensions
          -  calculate the **conditional** log-llh for each individual; accept the entire
             new vector of parameters according to this for each individual
         */

      }

      // ** 2nd proposal distribution
      for (size_t i = 0; i < _n2; i++)
      {

      /* Todo:
         What George's code does:
          - sample /per dimension/, but sample this dimension for all individuals at once
          - calculate the *total* log-likelihood /per individual/, then reject or accept that
            individual's parameter change according to that log-likelihood
         */
      }

      // ** update variances

      // ** 3rd proposal distribution
      for (size_t i = 0; i < _n3; i++)
      {
      // TODO
      }

      // ** update variances

    } // Chain end

  }



}

//* @brief Update internal distribution representation of p(latent | hyper), and anneal the covariance if needed.
void korali::solver::HSAEM::updateAnnealedDistribution(){
  if (_useSimulatedAnnealing){
    auto flatCov = flatten(_currentHyperparametersCovariance);
    for(size_t i = 0; i < flatCov.size(); i++)
      _annealedCovariance[i] = std::max(_annealedCovariance[i], flatCov[i]);
    _annealedNormalGenerator->setProperty("Sigma", _annealedCovariance);
  }
  else
    _annealedNormalGenerator->setProperty("Sigma", flatten(_currentHyperparametersCovariance));
  _annealedNormalGenerator->setProperty("Mean Vector", _currentHyperparametersMean);
  _annealedNormalGenerator->updateDistribution();
}


void korali::solver::HSAEM::updateS(){
}


void korali::solver::HSAEM::updateHyperparameters(){



}

void korali::solver::HSAEM::updateCholesky(){
}


void korali::solver::HSAEM::printGenerationBefore()
{
 _k->_logger->logInfo("Normal", "Preparing to start generation...\n");
}

void korali::solver::HSAEM::printGenerationAfter()
{
 _k->_logger->logInfo("Normal", "Finished to generation %lu...\n", _k->_currentGeneration);
}


/** @brief: Utility function to convert a vector of vectors into a concatenated 1D vector.
  */
std::vector<double>  korali::solver::HSAEM::flatten(const std::vector<std::vector<double>>& v)
{
  // credits to Sebastian Redl @ stackoverflow
  std::size_t total_size = 0;
  for (const auto& sub : v)
    total_size += sub.size();
  std::vector<double> result;
  result.reserve(total_size);
  for (const auto& sub : v)
    result.insert(result.end(), sub.begin(), sub.end());
  return result;
}
