*********************************************
SAEM Adjusted for Hierarchical Models
*********************************************

The Stochastic Approximation Expectation Maximization (SAEM) solver is targeted at
a very general form of latent variable problems. If a problem has a hierarchical
form:

.. math::

  p(X, \theta | \psi) = p(X | \theta) \cdot q(\theta | \psi)

Where:
 -  :math:`X = (x_i)_i` are observed data points
    (entirely dealt with by the user, only mentioned for clarity)
 -  :math:`\theta` are latent (i.e. unobserved) variables,
 -  :math:`\psi` are hyperparameters.

:math:`p(X | \theta )` **is given by the user** and can have arbitrary an form
(that is a - possibly unnormalized - probability distribution, i.e. it should have
a finite integral over :math:`X`).

:math:`p(\theta | \psi )` is **generated by Korali**. Each latent variable in :math:`\theta`
can be chosen to have a **normal**, **log-normal** or **logit-normal** distribution.
(Log-normal and logit-normal distributions refer to the log or logit of
:math:`\theta_i` being normally distributed.)


As opposed to SAEM, hSAEM implements sampling for the E-step internally, so no sampler
needs to be given by the user. # Todo: simulated annealing

We exactly follow the method described in section 9.2.4.1 in `Lavielle's book <http://www.cmap.polytechnique.fr/~lavielle/book.html>`_ .


## TODO: Describe how to use it or refer to a tutorial
------------------------------------------------------

You can add code:

.. code-block:: python
  
  print('Hello World')
  
or formulae:

.. math::

  y = x^2

And other rST devices.

