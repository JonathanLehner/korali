import sys
sys.path.append('./_model/logistic')
sys.path.append('./_model')
from model import *
from load_data import *
from utils import generate_variable

import numpy as np
import korali


def main():

  # * Load the data.
  #   It is stored together with other information such as data dimensions in object "d":
  d = LogisticData()

  k = korali.Engine()
  e = korali.Experiment()

  e["Problem"]["Type"] = "Bayesian/Latent/HierarchicalLatentReference"

  # The computational model for the log-likelihood, log[ p(data point | latent) ]
  e["Problem"][
      "Computational Model"] = lambda sample: logisticModelFunction(sample)
  e["Problem"]["Likelihood Model"] = "Normal"

  x_vals = [[] for _ in range(d.nIndividuals)]
  y_vals = [[] for _ in range(d.nIndividuals)]
  for i in range(d.nIndividuals):
    # data: (nInd x nPoints x nDim), with nDim = 3
    # We discard the first dimension: ID
    x_vals[i] = d.data[i, :, 1:2].tolist()
    y_vals[i] = d.data[i, :, 2].tolist()

  e["Problem"]["Data Points"] = x_vals
  e["Problem"]["Reference Data"] = y_vals
  e["Problem"]["Data Dimensions"] = d.nDataDimensions
  e["Problem"]["Number Individuals"] = d.nIndividuals
  e["Problem"]["Latent Space Dimensions"] = d.nLatentSpaceDimensions
  e["Problem"]["Initial Variance"] = 1

  e["Solver"]["Type"] = "HSAEM"
  e["Solver"]["Number Samples Per Step"] = 10
  e["Solver"]["mcmc Outer Steps"] = 1
  e["Solver"]["mcmc Target Acceptance Rate"] = 0.4
  e["Solver"]["N1"] = 2
  e["Solver"]["N2"] = 2
  e["Solver"]["N3"] = 2
  e["Solver"]["K1"] = 200
  e["Solver"]["Alpha 1"] = 0.25
  e["Solver"]["Alpha 2"] = 0.5
  e["Solver"]["Use Simulated Annealing"] = True
  e["Solver"]["Simulated Annealing Decay Factor"] = 0.95
  e["Solver"]["Simulated Annealing Initial Variance"] = 1
  e["Solver"]["Diagonal Covariance"] = True
  e["Solver"]["Termination Criteria"]["Max Generations"] = 150

  e["Distributions"][0]["Name"] = "Uniform 0"
  e["Distributions"][0]["Type"] = "Univariate/Uniform"
  e["Distributions"][0]["Minimum"] = -100
  e["Distributions"][0]["Maximum"] = 100

  e["Distributions"][1]["Name"] = "Uniform 1"
  e["Distributions"][1]["Type"] = "Univariate/Uniform"
  e["Distributions"][1]["Minimum"] = 0
  e["Distributions"][1]["Maximum"] = 100

  e["Distributions"][2]["Name"] = "Uniform 2"
  e["Distributions"][2]["Type"] = "Univariate/Uniform"
  e["Distributions"][2]["Minimum"] = 0.0
  e["Distributions"][2]["Maximum"] = 1.0

  # * Define the variables:
  #   We only define one prototype latent variable vector for individual 0.
  #   The others will be automatically generated by Korali, as well as all hyperparameters.
  if np.isscalar(d.transf):
    d.transf = [d.transf]
  if np.isscalar(d.err_transf):
    d.err_transf = [d.err_transf]
  dimCounter = 0
  distribs = {
      "Normal": "Uniform 0",
      "Log-Normal": "Uniform 1",
      "Logit-Normal": "Uniform 2",
      "Probit-Normal": "Uniform XX"
  }
  for transf in d.transf:
    generate_variable(
        transf,
        e,
        dimCounter,
        "latent parameter " + str(dimCounter),
        distribs,
        initial=d.beta[dimCounter])
    dimCounter += 1

  for i, err_transf in enumerate(d.err_transf):
    generate_variable(
        err_transf,
        e,
        dimCounter,
        "standard deviation " + str(i),
        distribs,
        initial=d.beta[dimCounter])
    dimCounter += 1

  assert dimCounter == d.dNormal + d.dLognormal + d.dLogitnormal + d.dProbitnormal

  e["File Output"]["Frequency"] = 1
  e["File Output"]["Path"] = "_korali_result_logistic/"
  e["Console Output"]["Frequency"] = 1
  e["Console Output"]["Verbosity"] = "Detailed"

  k.run(e)


if __name__ == '__main__':
  # # ** For debugging, try this: **
  # import sys, trace
  # sys.stdout = sys.stderr
  # tracer = trace.Trace(trace=1, count=0, ignoredirs=["/usr", sys.prefix])
  # tracer.runfunc(main)
  # # ** Else: **
  main()
